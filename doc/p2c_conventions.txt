Conventions for conversion of Pascaline programs to C

This document outlines some conventions used for conversion of Pascaline 
programs to C language. This is useful to me for conventions, anyone else for
their convertions, or for C programmers who want an explaination of the odd
constructs they see in the C code here.

CONVERTERS

p2c exists, but has several drawbacks:

1. It reformats the code quite a bit, requiring "unreformatting". This includes
things like kicking the controlled statement of an if () to the next line.

2. It dies (segfaults) on any incorrect source, I.E., it expects the source code
to be syntactically and semantically perfect.

3. It does not translate Pascaline, but only the Pascal subset.

It is for these reasons I have hand translated a lot of the code here. There are
other p2c type converters in existance, but I have found them wanting, for
various reasons:

- They place no value on producing clean, readable and commented C code, since
they are just designed to cross compile to C.

- There is no attempt to refactor the code into useable C code.

- They don't attempt to maintain formatting and commenting.

The "perfect" converter for me is thus yet to be written, and I will probably 
have to write it.

I have previously written a converter from C to Pascaline designed to convert
header files (ch2ph), and I know from that effort that a converter needs to be
formed from a true compiler front end, not just a search-and-substitute program.

CONVENTIONS

1. Because adapting boolean types is both sourcewide and because there is no set
convention for boolean in C (both use of 0 and 1 and the definitions TRUE and 
FALSE are seen) I have settled on the convention of declaring:

typedef enum boolean { false, true } boolean;

This both interoperates with C conventions and gives the constants false and 
true a proper value (0 and 1).

2. type to typedef. I have converted types in Pascaline to typedefs in C, even
if the resulting typedef is fairly useless. Example:

Pascaline:

type index = 1..10;

C:

typedef int index;

This is because C has no equivalent to ranged types. The idea of using a name
alias for a mundane integer is that it prevents the need to globally change all
all of the named types or factor them out. The types become memnomic equivalents
for types. It is perhaps one of the more annoying conversions, I will admit
(especially for C only programmers). However, the advantage is it leaves the
Pascaline and C source codes comparible side by side.

Update: I have given this considerable thought while hand translating these
programs. I think there is a case to "unwind" such type defines with the idea
of making the code "more C like". This is one of those things that makes more
sense for automated convertion than manual. To unwind a type definition back to,
say, simple integer could be a source wide convertion, since the type could be
used anywhere.

3. 1 based vs. 0 based. A lot of the code refactoring centers around the 
"misunderstanding" between 0 and 1 based arrays in C vs. Pascaline. Actually,
Pascaline can easily use 0 based indexes, and C could use 1 based indexes if you
discard the first element. However, both languages have their conventions.

The direct, translatable equivalent is to simply give -1 on all indexes:

Pascaline:

a[i]

C:

a[i-1]

I have refactored out the 0 index case in a lot of code, but in other cases not.
For example:

Pascaline:

for i := 1 to 10 do ...

C:

for (i = 1; i <= 10; i++) ...

Are directly equivalent. However:

Pascaline:

for i := 1 to 10 do a[i] = 0;

C:

for (i = 1; i <= 10; i++) a[i-1] = 0;

is unfortunate, so I prefer:

for (i = 0; i < 0; a[i] = 0;

Which better matches C conventions and is less verbose. It makes no difference
in the code whatever after the compiler optimizes it.

4. Arrays to pointers. I have made little or no effort to convert array notation
in the code to pointer notation:

Pascaline:

i := 1;

while a[i] = ' ' do i = i+1;

C:

i = 0;

while (a[i] == ' ') i++;

and not:

while (*a == ' ') i++;

The array notation is directly equivalent in C, and is more clear as to the 
programmer's intent, as well.

5. Strings. Pascaline allows for dynamic arrays as a type. In C this must be a 
pointer. Thus the convention I have used is:

Pascaline:

type string = packed array of char;

C:

typedef char* string;

This can result in a litte more work inside the code that uses the type, but the
code is basically equivalent.

6. Sets. The equivalent set types and operations for sets are:

#define MAXSET 32

typedef unsigned char set[MAXSET];

#define SET(s, b) (*(s+b/8) |= 1<<(b%8)) /* set bit in set */
#define RES(s, b) (*(s+b/8) &= ~(1<<(b%8)) /* reset bit in set */
#define INS(s, b) (!!(*(s+b/8) & 1<<(b%8))) /* check bit in set */

void setass(set* d, set* s) { int i; for (i = 0; i < MAXSET; i++) *d++ = *s++; } 
boolean setequ(set* a, set* b) 
{ boolean eq = true; int i; for (i = 0; i < MAXSET; i++) if (*d != *s) eq = false; 
  return eq; } 
void setclr(set* d) { int i; for (i = 0; i < MAXSET; i++) *d = 0;
  
Etc. Note 32 bytes gives 256 set elements.

In general, however, my preference is to factor out the use of sets, since it is
not really aligned with techniques in C. There are, in fact, several places
where sets are essential, and I note that even the Linux kernel uses them on
occasion. Thus you still may see them.

Any automated converter will, by definition, have to use routines or macros in
C for sets. The worst one is a constant set like:

s := [one, two, three];

which has to be refactored as:

setclr(s);
SET(s, one);
SET(s, two);
SET(s, three);

I.E., fairly ungainly.

There is another solution to this for sets that can fit in 32 or even 64 bits.
In this case the set fits into an unsigned integer or long integer, and becomes:

#define BIT(b) (1<<b) /* find bit from ordinal */
#define SET(s, b) (*s |= BIT(b)) /* set bit in set */
#define RES(s, b) (*s &= ~BIT(b)) /* reset bit in set */
#define INS(s, b) (!!(*s & BIT(b))) /* check bit in set */

IE, it degenerates to a common integer bit operation in C, which is in fact the
common usage in C. In this case, creating a set from elements in a single line is
possible:

s = BIT(a)|BIT(b)|BIT(c);

In fact, 32 or 64 bit sets will cover most sets. 64 bits was, in fact, the 
original set length of Pascal. The requirement was to enable "set of char", 
which on a CDC machine was 64 characters (upper and lower case were handled by
shift characters). This was commonly expanded to 256 bits to cover the ASCII 
character set (in extended form). Thus the majority of set cases can be 
converted to simple integer sets, and the N set version above covers the rest. 

4. Nested functions. The conversion of Pascaline nested functions to C is 
anywhere from very difficult to impossible. C99 has them in the standard, and
this is another case of C getting improved with Pascal style constructs, like
enums (no, Virgina, C didn't always have enums). The latest versions of GCC have
this feature, so I suspect the answer is to directly convert them

5. Constants. I have followed the convention of using #defines for constants, 
including expressions. This also means they have to be (or should be, to fit C
conventions) converted to upper case. I researched using const definitions in C
according to C99, but found various issues with doing that. I may revisit this.

6. Upper case/lower case. Because Pascaline treats upper and lower case equally,
you won't generally see upper or lower case used to differentiate symbols here
(see #4 "sets" for an exception to this rule). Speaking for myself I find using
case to differentiate symbols in C rather obnoxious in any case, and I don't use
it in pure C programs, either (I feel the same about struct vs. non-struct 
naming).

7. eoln() or eof() conversions. In order to convert the use of these functions
to C, this would require refactoring the code. And example of why is:

while not eof(f) do read(f, c);

Where c is char. To do this job in C using only whitebook calls, a refactor is
required:

while ((c = fgetc(f) != c);

Its a simple refactor, however it can cause changes that ripple through the 
code. For example:

while not eof(f) do readline();

Where readline() is a routine that reads in an entire line. We don't have access
to the buffer variable used in readline(), so a more extensive refactor is 
required.

One way around this, especially for automated translation is to make our own 
eoln() and eof() routines:

int eoln(FILE* f) { int c; ungetc(c = fgetc(f), f); return c == '\n'; }
int eof(FILE* f) { int c; ungetc(c = fgetc(f), f); return c == EOF; }

Note this uses the common definition of putting back EOF as having no effect, 
which indeed was why this rule came about. The whitebook does not actually
specify this behavior, but most implementations do, because it is the most
reasonable interpretation, that EOF as put back is simply ignored.

8. Non-reliance on expression evaluation order. This one is pretty simple, 
Pascaline does not rely on expression ordering. You are supposed to assume that
all of the expression parts are executed. This rule is downward compatible with
C, which is to say the expressions thus specified won't be wrong, they will just
appear as unnecessarily paranoid compared to normal C. Thus you may encounter
such oddly written expressions or statements.
